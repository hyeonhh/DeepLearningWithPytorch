# Chapter 7 새와 비행기 구별하기 : 이미지 학습 
## 7.1 작은 이미지를 모아놓은 데이터셋
### 7.1.1 CIFAR-10 다운로드
### 7.1.2 데이터셋 클래스
- 파이토치의 Dataset : `__len__` 와  `__getitem__` 을 구현하기 위해 필요한 객체이다
- `__len__` : 데이터셋의 아이템 수를 반환
- `__getitem__` : 샘플과 레이블(정수 인덱스)로 이루어진 아이템을 반환


### 7.1.3 데이터 변환
- 이제 PIL 이미지를 파이토치 텐서로 변환할 단계이다.
- 왜 변환해야하지?
  - 딥러닝 모델이 이미지를 tensor 형태로만 처리할 수 있기 때문이다.
  - PIL : 파이썬에서 이미지를 다루는 라이브러리 pilow에서 사용하는 데이터 타입
      - [높이, 너비 , 채널] 구조(HWC)
      - 픽셀 값이 0 ~ 255 범위의 정수
  - tensor : Pytorch 모델은 입력 데이터를 반드시 텐서 형태로 받아야함
      - [채널, 높이, 너비] 구조(CHW)
      - 픽셀 값이 0 ~ 1 범위의 실수(float)로 변환됨
- 변환 과정에서 일어나는일
  - 차원 구조 변경:  HWC -> CHW
  - 값의 범위 변경 : 0 ~ 255 -> 0 ~ 1로 정규화됨
  - 데이터 타입 변경 : PIL 이미지 -> torch.Tensor
- `torch.ToTensor()`
  
### 7.1.4 데이터 정규화 
- 데이터셋 정규화로 각 채널이 평균값 0과 단위 표준 편차를 가지게 한다.
- 데이터 정규화가 필요한 이유 :
  - 교재 설명 :  " -1과 1 혹은 -2와 2 사이에서 선형인 활성 함수를 택하고 데이터를 같은 범위에서 평균을 가지게한다면 뉴런은 0이 아닌 기울기를 가지게 되므로 빨리 학습할 수 있기 때문이다. " 
    -  활성 함수의 선형 구간과 정규화
      -  많은 활성 함수들은 입력값이 0 근처일 때 기울기가 크고, 입력이 너무 크거나 작으면 기울기가 거의 0(포화구간)이 된다
      -  만약 데이터를 -1 ~ 1 또는 -2 ~ 2 처럼 활성함수의 선형(민감)구간에 오도록 정규화하면 뉴런의 출력이 입력 변화에 따라 잘 반응하고, gradient도 충분히 커서 학습이 빠르고 잘 된다.
    -  평균을 0에 맞추는 이유
      - 데이터를 평균 0, 범위 -1~1로 맞추면, 대부분의 입력이 활성 함수의 민감한 구간에 위치하게 된다.
      - 이 때 뉴런의 출력은 0이 아닌 기울기를 가지므로, 오차가 역전파될 때 파라미터가 효과적으로 업데이트된다.
    - 정규화하지 않으면?
      - 입력값이 너무 크거나 작으면, 활성 함수가 포화구간에 들어가서 기울기가 거의 0이 된다.
  - 교재 설명 : "각 채널을 정규화해 동일한 분산을 가지게 되면 채널 정보가 동일한 학습률로 경사 하강을 통해 섞이고 업데이트되는 것을 보장할 수 있다"
    - 각 채널의 값 분포가 다르면 학습할 때 어떤 채널은 빠르게, 어떤 채널은 느리게 업데이트될 수 있다.
    - 그래서 각 채널별로 정규화해주면 모든 채널이 비슷한 스케일로 맞춰진다.

## 7.2 새와 비행기를 구별하기 
  ### 7.2.1 데이터셋 구축
  ### 7.2.2 완전 연결 모델 
  - 완전 연결 : 한 층의 모든 뉴런이 다음 층의 모든 뉴런과 연결되어있는 상태를 말한다.
  ### 7.2.3 분류기의 출력 
  - 출력을 "확률"로 해석할 수 있다.
  - softmax
  ### 7.2.4 출력을 확률로 표현하기
  - 소프트 맥스는 벡터값을 받아 동일한 차원의 벡터를 만드는데, 값이 확률로 표현되어야하는 제약을 만족시킨다.
  - `softmax = torch.exp(x) / torch.exp(x).sum()`
  - softmax는 어떤 차원을 기준으로 값을 구할 것인지 dim을 입력받는다.
    - dim = 1 이면 가로방향(열 방향으로) 값을 구한다.
    - dim = 0 이면 세로 방향(행 방향으로) 값을 구한다.
  - `tensor.permute` : 모든 차원을 맞교환할 수 있다.
    	- ex ) img.permute(1,2,0) <- img의 현재 차원이 C * H * W 순서라면 지정해준 정수에 맞춰서 H * W * C 로 바꿔준다.
	- "모델은 입력이 3072개의 피처를 가지고 있으며 0번 차원을 따라 배치로 이뤄지는 데이터를 대상으로 nn에서 작업하게 되어있다. 따라서 3*32*32 이미지를 1차원 텐서로 만들고 추가 차원을 0번 포지션에 넣어야한다." **이게 무슨말일까?**
   - nn.Linear(3072, ...) 같은 fully connected layer는 입력 데이터를 1차원 텐서로 받는 구조
   - pytorch의 nn은 입력 데이터의 0번 차원을 항상 배치 차원으로 인식한다.
   - 이미지 데이터의 기본 구조
     - 이미지 한장(RGB) : (3,32,32)
     - 여러 장의 이미지를 묶으면 : (배치 크기, 3,32,32)
   - Linear 레이어의 입력 형태
     - nn.Linear(3*32*32 ...)는 입력이 (배치, 3*32*32) 형태여야한다.
     -  즉 한 이미지를 1차원 벡터 (3*32*32,)으로 펼치고
     -  여러 이미지를 처리하려면 맨 앞(0번째)에 배치차원을 둬서 (배치, 3*32*32) 형식으로 맞춰줘야한다.
   - 어떻게 바꿀까?
     - 한 장 이미지는 img.view(-1).unsqueeze(0) -> (1,3*32*32)
     - 여러 장의 이미지는 imgs.view(batch_size,-1) -> (batch_size, 3*32*32)
       - 맨 앞 차원이 배치로, 나머지는 feature 벡터로 바꿔주는 것!
       - Pytorch 공식문서  Input: (∗,H_in )where ∗ means any number of dimensions including none and Hin=in_features H_in =in_features.
           - nn.Linear(in_features, out_features)는 입력에서 마지막 차원이 반드시 in_featurs여야한다.
           - * : 배치 차원을 포함하여 그 앞의 모든 차원(생략 가능, 1차원, 2차원 등등)을 의미한다.
  
 
### 7.2.5 분류를 위한 손실값 
 - MSE를 사용해서 출력 확률이 `[0.0 , 1.0]` ,`[1.0, 0.0]`에 수렴하도록 만들 수 있다.
 - 그러나 값을 정확하게 만드는게 중요하지 않고, 분류가 어긋난 경우에만 penalty를 줄 수 있다.
 - likelihood
   - 정답 클래스에 대한 확률 수치 (the probablity associated with the correct class)
   - likelihood가 낮을 때, 다른 클래스의 확률이 매우 높을 때 값이 커지는 손실함수가 필요하다.
 - NLL(Negative Log Likelihood) 함수
   - 위에서 likelihood가 낮을 때, 다른 클래스의 확률이 매우 높을 때 값이 커지는 손실함수가 필요하다고 했다.
   - 이런 식으로 동작하는 함수가 NLL 함수이다.
   - `NLL = - sum(log(out_i[c_i]))`
     - sum : N개의 샘플 합
     - c_i : 샘플 i에 대한 정답 클래스
     - NLL은 확률을 입력받기 때문에 likelihood가 증가하면 다른 확률은 필연적으로 줄어든다. 
 - 파이토치는 nn.NLLLoss 클래스를 제공한다.
   - 입력을 확률이 아니라 "로그 확률의 텐서"로 받는다.
   - 만약 입력값이 그냥 확률 (0~1)이라면 log(0)에 가까운 값이 나오면서 수치적으로 불안정해질 수 있다.
   - 왜 Softmax 대신 LogSoftmax를 쓰는가?
     - Softmax는 모델의 출력을 확률(0~1)로 변환해주지만 NLLLoss에 바로 넣으면 log(0) 문제 등으로 계산이 불안정해질 수 있다.
       - log(0)을 계산하면 -무한대가 나오기 때문이다!  이 값이 gradient 계산 과정에서 Nan이나 inf 오류를 발생시킬 수 있다. 
     - LogSoftmax는 softmax를 적용한 뒤 바로 log를 취해서, 곱셈 나눗셈 대신 덧셈 뺄셈으로 계산을 단순화하고 log-sum-exp 트릭을 통해 수치적으로 훨씬 안정적인 연산이 가능해진다.
     - 즉 확률이 아주 작아도 log-softmax는 underflow없이 안전하게 계산된다.
  - 크로스 엔트로피 손실 vs MSE
    - 크로스 엔트로피는 예측이 타깃에서 멀어지는 경우 그래프의 경사가 적당히 생기지만 MSE는 경사가 훨씬 더 일찍 포화)되어 좋지 않은 예측을 하게 된다.
      - MSE는 경사가 훨씬 더 빨리 평탄해지고 틀린 예측에 대해 파라미터를 크게 업데이트하지 않는다.
      - MSE의 기울기는 잘못된 예측에 대한 소프트 맥스 함수의 평탄화를 보상하기에 너무 작다.
        - 소프트맥스의 평탄화
          - 소프트 맥스 함수는 모델의 출력값(logit)을 확률로 변환할 때, 여러 클래스 점수 차이가 크지 않으면 출력 확률이 비슷하게 분포된다.
          -  소프트 맥스가 평탄하게 만들어버린 확률 분포에 대해 MSE는 조금만 패널티를 주고, 모델이 잘못된 예측을 고치기 어려게 만든다.
          -  크로스 엔트로피는 정답 확률이 0에 가까울수록 손실이 급격히 커지고, gradient(경사)도 커져서 파라미터가 빠르게 올바른 방향으로 업데이트된다.
        - ex) 정답이 1인데 예측이 0.001일 때:
          - MSE: (1 - 0.001)^2 ≈ 0.998
          - Cross Entropy: -log(0.001) ≈ 6.9 (매우 큰 손실)

      - 따라서 분류 문제에서는 크로스 엔트로피가 효과적이다!
      - nn.LogSoftmax와 nn.NLLLoss 조합은 == nn.CrossEntropyLoss
        - NLLLoss는 입력으로 로그 확률 예측을 받는다.
        - CrossEntropyLoss는 logits이라는 점수를 입력받는다.
    
### 7.2.6 분류기 훈련 
  - 코드 참조
  - 미니 배치
    - DataLoader : 미니 배치의 데이터를 섞거나 구조화하는 작업을 돕는 클래스
    - for imgs, labels in DataLoader 객체:
      - 배치 크기 만큼의 imgs, labels가 나온다.
  - 음의 로그 가능도(negative log likelihood)
    - 크로스 엔트로피는 타깃의 분포에 대한 예측 분포로서 nll로 해석될 수 있다.
    - 로그 가능도는 모델이 데이터를 얼마나 잘 설명하는지 나타내는 값
    - 확률 모델에서, 데이터가 나올 확률(가능도)를 계산한 후 그 값에 로그를 취해 더하기 쉽게 만든 것
    - 음의 로그 가능도는 이 값에 음수를 붙인 것
    - 확률이 높을수록 NLL값이 작아져서 NLL을 최소화하는 것이 모델을 잘 학습시키는 것과 같다.
    - 크로스 엔트로피는 두 확률 분포 P(실제 정답)과 Q(모델 예측)사이의 차이를 측정하는 함수이다.
      - H(P,Q) = - sum(P(x_i) * log(Q(x_i))
      - 분류문제에서 타깃 P는 보통 원 핫 벡터로 표현된다.
      - 이 경우 크로스 엔트로피는 정답 클래스의 예측 확률만 남아서
      - H(P,Q) = - log(Q(x_i)) 로 표현되고 이제 바로 NLL와 같은 형태가 된다.
        
### 완전 연결의 한계
- 이미지를 1차원으로 놓고 선형 모듈을 사용하는 방식에 대해 생각해보면,,,
  - 입력으로 들어오는 RGB 이미지의 모든 정보 하나하나를 사용하며 출력 피처 하나하나에 대해 각 정보의 선형 조합을 계산한다.
  - using a linear module on a 1D view of out image entails
  - 픽셀 하나마다 다른 모든 픽셀과의 조합을 고려하고 있지만 상대적으로 가까운 위치나 먼 위치에 있는 점을 사용하지 않고(공간적 정보는 무시하고) 이미지를 하나의 큰 숫자 벡터로 취급하고 있다.
  - 완전 연결 신경망은 평행 이동 불변성이 없다.
    - 위치 4,4에서 시작하는 전투기를 인식하도록 훈련된 신경망은 위치 8,8에 나타난 동일한 전투기를 인식할 수 없다는 의미
  - 이를 보완하려면 데이터셋 증강(augmentation)이 필요하다.
    - 훈련 때 이미지를 랜덤하게 평행이동시켜서 이미지의 모든 영역에서 전투기를 보게 해야하고, 이 작업을 데이터셋의 모든 이미지에 대해 수행해야한다.  
### 다음 챕터 예고
- 훨씬 더 나은 결과를 얻기 위해 이미지 데이터의 2차원 특성을 어떻게 활용할 수 있을까?





